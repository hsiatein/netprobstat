#align(center)[
  #text(size: 32pt)[网络数据的概率与统计方法]
  #v(0cm)
  #text(size: 32pt)[Homework 1]
  #v(2cm)
  #text(size: 18pt)[夏添]
]

#pagebreak()

= 2.1

== 2.1.a

$2 arrow.r 4 arrow.r 5 arrow.r 4 arrow.r 7$

== 2.1.b

$2 arrow.r 4 arrow.r 6 arrow.r 5 arrow.r 4 arrow.r 7$

== 2.1.c

$2 arrow.r 4 arrow.r 7$

== 2.1.d

14条path, 计算方法可见2.1.d.jl程序

[1, 2, 4, 7],
[1, 2, 4, 6, 7],
[1, 3, 2, 4, 7],
[1, 3, 5, 4, 7],
[1, 3, 5, 6, 7],
[1, 2, 3, 5, 4, 7],
[1, 2, 3, 5, 6, 7],
[1, 2, 4, 5, 6, 7],
[1, 3, 2, 4, 6, 7],
[1, 3, 5, 4, 6, 7],
[1, 3, 5, 6, 4, 7],
[1, 2, 3, 5, 4, 6, 7],
[1, 2, 3, 5, 6, 4, 7],
[1, 3, 2, 4, 5, 6, 7]

测地线为[1, 2, 4, 7], 为唯一的最短路

== 2.1.e

除去空图和自身, 共$2^7-2=126$个子图, 遍历这些图来检测是否连通或有环.使用Julia的Graphs包来计算, 见2.1.e.jl程序.

连通子图数量: 72

含有长度大于等于3的环的子图数量: 38

含有长度为4的环的子图数量: 7

#v(2cm)

= 2.2

使用Julia的Graphs包来实现, ulia是数学友好的通用编程语言, raphs包是官方推荐的图包, .2.jl程序是使用其计算每两个点间最短路径的示例.

#v(2cm)

= 2.3

== 2.3.a

使用Julia的LinearAlgebra包来计算, 值验证的代码见2.3.a.jl程序.

L特征值 = [-1.84951145962554e-16, 0.8143492057686633, 2.328009014103823, 3.3139076014894115, 3.5980893488274437, 4.457529630368829, 5.488115199441825]

L_normalized特征值 = [-7.513521055324546e-17, 0.3245847383727133, 0.8984443816389692, 1.1547282022414804, 1.3965736219147333, 1.5184322609218541, 1.70723679491025]

第一个特征值均为0, 浮点误差

== 2.3.b

使用Julia的LinearAlgebra包来计算, 值验证的代码见2.3.b.jl程序.第二小的特征值对应特征向量为[-0.5600988036709549, -0.3161832627190568, -0.34789832870143056, 0.21693093308782505, 0.11589780795197868, 0.38427953161352074, 0.5070721224381334], 据符号, 以分成两组: [1,2,3]和[4,5,6,7].

== 2.3.c

b中计算出特征值0.8143492057686732

特征向量[-0.5600988036709549, -0.3161832627190568, -0.34789832870143056, 0.21693093308782505, 0.11589780795197868, 0.38427953161352074, 0.5070721224381334]

在1和7间加一条边, 见2.3.c.jl程序, 特征值1.5857864376269077, 增加了

特征向量[-0.42357699884528544, -0.4235769988452842, -0.4235769988452853, 0.24812566121427737, 0.24812566121427615, 0.5263540128930321, 0.24812566121427612]

= 2.4

== 2.4.a

#align(center)[
  $& dash(X) = 1 / n sum_(i=1)^n X_i\
  &E(dash(X)) = E(1 / n sum_(i=1)^n X_i)\
  &= 1 / n sum_(i=1)^n E(X_i)\
  &= 1 / n sum_(i=1)^n alpha\
  &= (n alpha) / n\
  &= alpha$
]

== 2.4.b

一个显然的事实$Sigma_(i j)=Sigma_(j i)$, 因此
#align(center)[
  $& H = 1/n (1,1,1,...,1)^T\
  &V(dash(X)) = V(H^T X) = H^T V(X) H\
  &= H^T Sigma H\
  &= 1/n^2 bold(1)^T Sigma bold(1)\
  &= 1/n^2 sum_(i=1)^n sum_(j=1)^n Sigma_(i j)\
  &= 1/n^2 sum_(i=1)^n Sigma_(i i) + 2 sum_(i<j) Sigma_(i j)$
]

== 2.4.c

由于$Sigma_(i i)= sigma^2$, 并且$Sigma_(i j)=0$, 因此代入b的结果
#align(center)[
  $& V(dash(X)) = 1/n^2 sum_(i=1)^n Sigma_(i i)\
  &= 1/n^2 sum_(i=1)^n sigma^2\
  &= n sigma^2 / n^2\
  &= sigma^2 / n$
]

= 2.5

== 2.5.a

#align(center)[
  $&log f(beta bar Y=y,X)\
  &= - sum_(i=1)^n (y_i - bold(x_i)^T beta)^2 -lambda sum_(i=1)^p beta_i^2\
  &= - (y-X beta)^T (y-X beta)- lambda beta^T beta\
  &= -y^T y + 2y^T X beta - beta^T X^T X beta - lambda beta^T beta\
  &= -y^T y + 2y^T X beta - beta^T (X^T X + lambda I) beta\
  &partial/(partial beta) log f(beta bar Y=y,X)\
  &= 2 X^T y - 2 (X^T X + lambda I) beta=0\
  &hat(beta)^"ridge"=(X^T X + lambda I)^(-1) X^T y$
]

== 2.5.b

部分模型 (X1,X2) 系数: [0.7683105225704386, 1.4060895533929763]

完整模型 (X1,X2,X3) 系数: [-7.035446481930445, -6.328223394120955, 15.524648813420935]

λ = 0.01 时, 岭回归系数 = [-0.0010129415887092808, 0.643183061172377, 1.530291432732362]

λ = 0.1 时, 岭回归系数 = [0.35933184694098774, 0.9966819479649155, 0.8044820288319421]

λ = 1.0 时, 岭回归系数 = [0.3751273573719772, 0.9780895211434281, 0.6886764083819131]

λ = 10.0 时, 岭回归系数 = [0.24268792790264382, 0.6354672539173319, 0.43988337443984227]

λ = 100.0 时, 岭回归系数 = [0.05292783866687759, 0.14041193949593814, 0.09669123215904768]